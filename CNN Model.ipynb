{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 115 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "data_dir= r'C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash'\n",
    "#Load the dataset from the directory\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),  # Resize images to a uniform size\n",
    "    batch_size=32,          # Define batch size\n",
    "    label_mode='int'        # Specify label type (int, categorical, etc.)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 1.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 10.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 11.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 2.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 3.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 4.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 5.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 6.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 7.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 8.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 9.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (1).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (10).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (11).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (12).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (13).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (14).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (2).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (3).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (4).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (5).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (6).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (7).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (8).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Avinash Images/avinash (9).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (1).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (10).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (11).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (12).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (13).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (14).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (15).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (16).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (17).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (18).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (2).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (3).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (4).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (5).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (6).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (7).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (8).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/bhanu/bhanu (9).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (1).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (10).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (11).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (12).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (13).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (14).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (15).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (16).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (17).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (18).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (19).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (2).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (20).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (21).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (22).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (23).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (24).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (3).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (4).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (5).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (6).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (7).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (8).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/Bhanuprasad/prasad (9).jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_100.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_101.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_102.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_103.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_104.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_105.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_106.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_107.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_108.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_109.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_110.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_111.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_112.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_113.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_114.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_115.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_116.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_117.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_118.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_119.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_84.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_85.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_86.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_87.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_88.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_89.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_90.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_91.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_92.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_93.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_94.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_95.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_96.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_97.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_98.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ramesh/frame_99.jpg')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.glob('*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ashrith=list(data_dir.glob('ashrith/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 1.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 10.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 11.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 2.jpg'),\n",
       " WindowsPath('C:/Deeplearning/genenv/Data science/Deep Learning/project 1/Avinash/ashrith/ashrith 3.jpg')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashrith[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "\n",
    "# PIL.Image.open(ashrith[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_images_dict = {\n",
    "    'ashrith': list(data_dir.glob('ashrith/*')),\n",
    "    'Avinash Images': list(data_dir.glob('Avinash Images/*')),\n",
    "    'bhanu': list(data_dir.glob('bhanu/*')),\n",
    "    'bhanuprasad': list(data_dir.glob('bhanuprasad/*')),\n",
    "    'manikanta': list(data_dir.glob('manikanta/*')),\n",
    "    'ramesh': list(data_dir.glob('ramesh/*'))\n",
    "}\n",
    "person_labels_dict = {\n",
    "    'ashrith': 0,\n",
    "    'Avinash Images': 1,\n",
    "    'bhanu': 2,\n",
    "    'bhanuprasad':3,\n",
    "    'manikanta': 4,\n",
    "    'ramesh': 5,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Deeplearning\\\\genenv\\\\Data science\\\\Deep Learning\\\\project 1\\\\Avinash\\\\ashrith\\\\ashrith 10.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(person_images_dict['ashrith'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(str(person_images_dict['ashrith'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        ...,\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165]],\n",
       "\n",
       "       [[228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        ...,\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165]],\n",
       "\n",
       "       [[228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        [228,  66,  38],\n",
       "        ...,\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165],\n",
       "        [160, 161, 165]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[145, 174, 159],\n",
       "        [147, 176, 161],\n",
       "        [149, 178, 163],\n",
       "        ...,\n",
       "        [ 71,  99,  69],\n",
       "        [ 74, 105,  74],\n",
       "        [ 77, 108,  77]],\n",
       "\n",
       "       [[146, 175, 160],\n",
       "        [147, 176, 161],\n",
       "        [150, 179, 164],\n",
       "        ...,\n",
       "        [ 66,  94,  64],\n",
       "        [ 70,  98,  68],\n",
       "        [ 73, 101,  71]],\n",
       "\n",
       "       [[146, 175, 160],\n",
       "        [147, 176, 161],\n",
       "        [150, 179, 164],\n",
       "        ...,\n",
       "        [ 62,  90,  60],\n",
       "        [ 66,  94,  64],\n",
       "        [ 68,  96,  66]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 3024, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.resize(img,(120,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.open(img)\n",
    "# the error is because the image in the formate of array formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# image=Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.show()\n",
    "# it  will display the image as pop up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image)\n",
    "# it will \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ashrith\n",
      "11\n",
      "Avinash Images\n",
      "14\n",
      "bhanu\n",
      "18\n",
      "bhanuprasad\n",
      "24\n",
      "manikanta\n",
      "12\n",
      "ramesh\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for person_name,images in person_images_dict.items():\n",
    "    print(person_name)\n",
    "    print (len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for person_name,images in person_images_dict.items():\n",
    "    for image in images:\n",
    "        img=cv2.imread(str(image))\n",
    "        resized=cv2.resize(img,(120,120))\n",
    "        x.append(resized)\n",
    "        y.append(person_labels_dict[person_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=X_train/255\n",
    "x_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model using cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=cnn=Sequential([\n",
    "    layers.Conv2D(30,3,padding='same',activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(15,3,padding='same',activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(15,3,padding='same',activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - acc: 0.1073 - loss: 39.3232\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - acc: 0.3191 - loss: 14.7111\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - acc: 0.4852 - loss: 3.6528\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - acc: 0.7057 - loss: 2.1407\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - acc: 0.6605 - loss: 1.7642\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - acc: 0.6807 - loss: 1.1947\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - acc: 0.7413 - loss: 1.0317\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - acc: 0.8528 - loss: 0.6263\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - acc: 0.8738 - loss: 0.3443\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - acc: 0.9112 - loss: 0.2839\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - acc: 0.9642 - loss: 0.0785\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - acc: 1.0000 - loss: 0.0545\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - acc: 1.0000 - loss: 0.0428\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - acc: 1.0000 - loss: 0.0461\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - acc: 1.0000 - loss: 0.0221\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - acc: 1.0000 - loss: 0.0180\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - acc: 1.0000 - loss: 0.0125\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - acc: 1.0000 - loss: 0.0088\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - acc: 1.0000 - loss: 0.0052\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - acc: 1.0000 - loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1788a6e78c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train,y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - acc: 0.2174 - loss: 2.2542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.254232406616211, 0.21739129722118378]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "cnn.save('model_name.h5')  # Save as HDF5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# # Load your trained model\n",
    "# model = tf.keras.models.load_model(r'C:\\Deeplearning\\genenv\\Data science\\Deep Learning\\project 1\\model_name.h5')\n",
    "\n",
    "# # Function to preprocess the frame for the model\n",
    "# def preprocess_frame(frame):\n",
    "#     frame_resized = cv2.resize(frame, (120, 120))  # Resize to match input shape of the model\n",
    "#     frame_normalized = frame_resized.astype('float32') / 255.0  # Normalize\n",
    "#     frame_expanded = np.expand_dims(frame_normalized, axis=0)  # Add batch dimension\n",
    "#     return frame_expanded\n",
    "\n",
    "# # Initialize the webcam (0 is the default camera)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Check if the webcam is opened correctly\n",
    "# if not cap.isOpened():\n",
    "#     raise Exception(\"Could not open video device\")\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()  # Capture frame-by-frame\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Preprocess the frame\n",
    "#     preprocessed_frame = preprocess_frame(frame)\n",
    "\n",
    "#     # Make prediction\n",
    "#     prediction = model.predict(preprocessed_frame)\n",
    "#     class_index = np.argmax(prediction)  # Get the index of the highest probability class\n",
    "\n",
    "#     # Draw the class label on the frame\n",
    "#     cv2.putText(frame, f'Class: {class_index}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "#     # Display the frame\n",
    "#     cv2.imshow('Video', frame)\n",
    "\n",
    "#     # Break the loop on 'q' key press\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the camera and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
